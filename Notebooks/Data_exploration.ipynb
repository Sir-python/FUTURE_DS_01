{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e5fa17",
   "metadata": {},
   "source": [
    "# **Libraries and File Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8fdff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(r\"F:\\Personal Works\\Future Interns\\FUTURE_DS_01\\Scripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0c0433",
   "metadata": {},
   "source": [
    "# **Dataset loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b9b0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"F:\\Personal Works\\Future Interns\\FUTURE_DS_01\\Dataset\\Raw data\\sentimentdataset.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dc4795c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0.1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "User",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Platform",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Hashtags",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Retweets",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Likes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Day",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Hour",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c678bd24-e8da-4165-86d3-f3f947588459",
       "rows": [
        [
         "0",
         "0",
         "0",
         " Enjoying a beautiful day at the park!              ",
         " Positive  ",
         "1/15/2023 12:30",
         " User123      ",
         " Twitter  ",
         " #Nature #Park                            ",
         "15",
         "30",
         " USA      ",
         "2023",
         "1",
         "15",
         "12"
        ],
        [
         "1",
         "1",
         "1",
         " Traffic was terrible this morning.                 ",
         " Negative  ",
         "1/15/2023 8:45",
         " CommuterX    ",
         " Twitter  ",
         " #Traffic #Morning                        ",
         "5",
         "10",
         " Canada   ",
         "2023",
         "1",
         "15",
         "8"
        ],
        [
         "2",
         "2",
         "2",
         " Just finished an amazing workout! ðŸ’ª               ",
         " Positive  ",
         "1/15/2023 15:45",
         " FitnessFan   ",
         " Instagram ",
         " #Fitness #Workout                        ",
         "20",
         "40",
         " USA        ",
         "2023",
         "1",
         "15",
         "15"
        ],
        [
         "3",
         "3",
         "3",
         " Excited about the upcoming weekend getaway!        ",
         " Positive  ",
         "1/15/2023 18:20",
         " AdventureX   ",
         " Facebook ",
         " #Travel #Adventure                       ",
         "8",
         "15",
         " UK       ",
         "2023",
         "1",
         "15",
         "18"
        ],
        [
         "4",
         "4",
         "4",
         " Trying out a new recipe for dinner tonight.        ",
         " Neutral   ",
         "1/15/2023 19:55",
         " ChefCook     ",
         " Instagram ",
         " #Cooking #Food                           ",
         "12",
         "25",
         " Australia ",
         "2023",
         "1",
         "15",
         "19"
        ],
        [
         "5",
         "5",
         "5",
         " Feeling grateful for the little things in life.    ",
         " Positive  ",
         "1/16/2023 9:10",
         " GratitudeNow ",
         " Twitter  ",
         " #Gratitude #PositiveVibes              ",
         "25",
         "50",
         " India    ",
         "2023",
         "1",
         "16",
         "9"
        ],
        [
         "6",
         "6",
         "6",
         " Rainy days call for cozy blankets and hot cocoa.   ",
         " Positive  ",
         "1/16/2023 14:45",
         " RainyDays    ",
         " Facebook ",
         " #RainyDays #Cozy                         ",
         "10",
         "20",
         " Canada   ",
         "2023",
         "1",
         "16",
         "14"
        ],
        [
         "7",
         "7",
         "7",
         " The new movie release is a must-watch!             ",
         " Positive  ",
         "1/16/2023 19:30",
         " MovieBuff    ",
         " Instagram ",
         " #MovieNight #MustWatch                  ",
         "15",
         "30",
         " USA    ",
         "2023",
         "1",
         "16",
         "19"
        ],
        [
         "8",
         "8",
         "8",
         " Political discussions heating up on the timeline.  ",
         " Negative  ",
         "1/17/2023 8:00",
         " DebateTalk   ",
         " Twitter  ",
         " #Politics #Debate                       ",
         "30",
         "60",
         " USA      ",
         "2023",
         "1",
         "17",
         "8"
        ],
        [
         "9",
         "9",
         "9",
         " Missing summer vibes and beach days.               ",
         " Neutral   ",
         "1/17/2023 12:20",
         " BeachLover   ",
         " Facebook ",
         " #Summer #BeachDays                      ",
         "18",
         "35",
         " Australia ",
         "2023",
         "1",
         "17",
         "12"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/15/2023 12:30</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Traffic was terrible this morning.           ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1/15/2023 8:45</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Just finished an amazing workout! ðŸ’ª          ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/15/2023 15:45</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/15/2023 18:20</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1/15/2023 19:55</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Feeling grateful for the little things in lif...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/16/2023 9:10</td>\n",
       "      <td>GratitudeNow</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Gratitude #PositiveVibes</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>India</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Rainy days call for cozy blankets and hot coc...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/16/2023 14:45</td>\n",
       "      <td>RainyDays</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#RainyDays #Cozy</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>The new movie release is a must-watch!       ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/16/2023 19:30</td>\n",
       "      <td>MovieBuff</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#MovieNight #MustWatch</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Political discussions heating up on the timel...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1/17/2023 8:00</td>\n",
       "      <td>DebateTalk</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Politics #Debate</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Missing summer vibes and beach days.         ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1/17/2023 12:20</td>\n",
       "      <td>BeachLover</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Summer #BeachDays</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "2             2           2   \n",
       "3             3           3   \n",
       "4             4           4   \n",
       "5             5           5   \n",
       "6             6           6   \n",
       "7             7           7   \n",
       "8             8           8   \n",
       "9             9           9   \n",
       "\n",
       "                                                Text    Sentiment  \\\n",
       "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
       "1   Traffic was terrible this morning.           ...   Negative     \n",
       "2   Just finished an amazing workout! ðŸ’ª          ...   Positive     \n",
       "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
       "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
       "5   Feeling grateful for the little things in lif...   Positive     \n",
       "6   Rainy days call for cozy blankets and hot coc...   Positive     \n",
       "7   The new movie release is a must-watch!       ...   Positive     \n",
       "8   Political discussions heating up on the timel...   Negative     \n",
       "9   Missing summer vibes and beach days.         ...   Neutral      \n",
       "\n",
       "         Timestamp            User     Platform  \\\n",
       "0  1/15/2023 12:30   User123          Twitter     \n",
       "1   1/15/2023 8:45   CommuterX        Twitter     \n",
       "2  1/15/2023 15:45   FitnessFan      Instagram    \n",
       "3  1/15/2023 18:20   AdventureX       Facebook    \n",
       "4  1/15/2023 19:55   ChefCook        Instagram    \n",
       "5   1/16/2023 9:10   GratitudeNow     Twitter     \n",
       "6  1/16/2023 14:45   RainyDays        Facebook    \n",
       "7  1/16/2023 19:30   MovieBuff       Instagram    \n",
       "8   1/17/2023 8:00   DebateTalk       Twitter     \n",
       "9  1/17/2023 12:20   BeachLover       Facebook    \n",
       "\n",
       "                                     Hashtags  Retweets  Likes       Country  \\\n",
       "0   #Nature #Park                                    15     30     USA         \n",
       "1   #Traffic #Morning                                 5     10     Canada      \n",
       "2   #Fitness #Workout                                20     40   USA           \n",
       "3   #Travel #Adventure                                8     15     UK          \n",
       "4   #Cooking #Food                                   12     25    Australia    \n",
       "5     #Gratitude #PositiveVibes                      25     50     India       \n",
       "6   #RainyDays #Cozy                                 10     20     Canada      \n",
       "7    #MovieNight #MustWatch                          15     30       USA       \n",
       "8    #Politics #Debate                               30     60     USA         \n",
       "9    #Summer #BeachDays                              18     35    Australia    \n",
       "\n",
       "   Year  Month  Day  Hour  \n",
       "0  2023      1   15    12  \n",
       "1  2023      1   15     8  \n",
       "2  2023      1   15    15  \n",
       "3  2023      1   15    18  \n",
       "4  2023      1   15    19  \n",
       "5  2023      1   16     9  \n",
       "6  2023      1   16    14  \n",
       "7  2023      1   16    19  \n",
       "8  2023      1   17     8  \n",
       "9  2023      1   17    12  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4845ec",
   "metadata": {},
   "source": [
    "# **Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f28f2021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 732 entries, 0 to 731\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0.1  732 non-null    int64 \n",
      " 1   Unnamed: 0    732 non-null    int64 \n",
      " 2   Text          732 non-null    object\n",
      " 3   Sentiment     732 non-null    object\n",
      " 4   Timestamp     732 non-null    object\n",
      " 5   User          732 non-null    object\n",
      " 6   Platform      732 non-null    object\n",
      " 7   Hashtags      732 non-null    object\n",
      " 8   Retweets      732 non-null    int64 \n",
      " 9   Likes         732 non-null    int64 \n",
      " 10  Country       732 non-null    object\n",
      " 11  Year          732 non-null    int64 \n",
      " 12  Month         732 non-null    int64 \n",
      " 13  Day           732 non-null    int64 \n",
      " 14  Hour          732 non-null    int64 \n",
      "dtypes: int64(8), object(7)\n",
      "memory usage: 85.9+ KB\n",
      "None\n",
      "       Unnamed: 0.1  Unnamed: 0    Retweets       Likes         Year  \\\n",
      "count    732.000000  732.000000  732.000000  732.000000   732.000000   \n",
      "mean     366.464481  369.740437   21.508197   42.901639  2020.471311   \n",
      "std      211.513936  212.428936    7.061286   14.089848     2.802285   \n",
      "min        0.000000    0.000000    5.000000   10.000000  2010.000000   \n",
      "25%      183.750000  185.750000   17.750000   34.750000  2019.000000   \n",
      "50%      366.500000  370.500000   22.000000   43.000000  2021.000000   \n",
      "75%      549.250000  553.250000   25.000000   50.000000  2023.000000   \n",
      "max      732.000000  736.000000   40.000000   80.000000  2023.000000   \n",
      "\n",
      "            Month         Day        Hour  \n",
      "count  732.000000  732.000000  732.000000  \n",
      "mean     6.122951   15.497268   15.521858  \n",
      "std      3.411763    8.474553    4.113414  \n",
      "min      1.000000    1.000000    0.000000  \n",
      "25%      3.000000    9.000000   13.000000  \n",
      "50%      6.000000   15.000000   16.000000  \n",
      "75%      9.000000   22.000000   19.000000  \n",
      "max     12.000000   31.000000   23.000000  \n",
      "Unnamed: 0.1    0\n",
      "Unnamed: 0      0\n",
      "Text            0\n",
      "Sentiment       0\n",
      "Timestamp       0\n",
      "User            0\n",
      "Platform        0\n",
      "Hashtags        0\n",
      "Retweets        0\n",
      "Likes           0\n",
      "Country         0\n",
      "Year            0\n",
      "Month           0\n",
      "Day             0\n",
      "Hour            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18c1dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0.1', 'Unnamed: 0', 'Year', 'Month', 'Day', 'Hour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4a25b0",
   "metadata": {},
   "source": [
    "# **Cleaning and Normalizing Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02170c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df231c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_text import *\n",
    "# df['cleaned_text'] = df['Text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5730071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['Text'].apply(clean_and_featurize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91391f5",
   "metadata": {},
   "source": [
    "# **Sentiment computation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2cb1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compute_sentiment import analyze_sentiment\n",
    "\n",
    "df[['polarity','subjectivity']] = df['clean_text'].apply(analyze_sentiment)\n",
    "df['sentiment_label'] = df['polarity'].apply(lambda p: 'positive' if p>0 else ('negative' if p<0 else 'neutral'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c7c149",
   "metadata": {},
   "source": [
    "# **Topic Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a302544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e552ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2938241   0.5200062   0.07613966 ... -0.06446401 -0.07984303\n",
      "   0.00698649]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.00611604 -0.00572963  0.00428719 ... -0.04205111 -0.0690875\n",
      "  -0.0935077 ]\n",
      " ...\n",
      " [ 0.11892192 -0.00173365 -0.005133   ...  0.05786044 -0.0486105\n",
      "   0.05188775]\n",
      " [ 0.06456202 -0.03633924 -0.04099568 ...  0.01653352 -0.02598497\n",
      "  -0.05781147]\n",
      " [ 0.09287211 -0.05662307 -0.00062428 ... -0.01216303  0.04603964\n",
      "   0.03658817]] \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to NMF initialization.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtopic_extraction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extraction_pipeline\n\u001b[1;32m----> 3\u001b[0m df_1 \u001b[38;5;241m=\u001b[39m \u001b[43mextraction_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Personal Works\\Future Interns\\FUTURE_DS_01\\Scripts\\topic_extraction.py:64\u001b[0m, in \u001b[0;36mextraction_pipeline\u001b[1;34m(df, text_col, n_topics, ngram_range, max_df, min_df, svd_components, random_state)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# NMF\u001b[39;00m\n\u001b[0;32m     63\u001b[0m nmf \u001b[38;5;241m=\u001b[39m NMF(n_components\u001b[38;5;241m=\u001b[39mn_topics, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m---> 64\u001b[0m W_nmf \u001b[38;5;241m=\u001b[39m \u001b[43mnmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnmf_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic_id_nmf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m W_nmf\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     66\u001b[0m terms_nmf \u001b[38;5;241m=\u001b[39m tfidf_vec\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\decomposition\\_nmf.py:1640\u001b[0m, in \u001b[0;36mNMF.fit_transform\u001b[1;34m(self, X, y, W, H)\u001b[0m\n\u001b[0;32m   1635\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m   1636\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m   1637\u001b[0m )\n\u001b[0;32m   1639\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(assume_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 1640\u001b[0m     W, H, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreconstruction_err_ \u001b[38;5;241m=\u001b[39m _beta_divergence(\n\u001b[0;32m   1643\u001b[0m     X, W, H, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beta_loss, square_root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1644\u001b[0m )\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_ \u001b[38;5;241m=\u001b[39m H\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\decomposition\\_nmf.py:1702\u001b[0m, in \u001b[0;36mNMF._fit_transform\u001b[1;34m(self, X, y, W, H, update_H)\u001b[0m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1696\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen beta_loss <= 0 and X contains zeros, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1697\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe solver may diverge. Please add small values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1698\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto X, or use a positive beta_loss.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1699\u001b[0m     )\n\u001b[0;32m   1701\u001b[0m \u001b[38;5;66;03m# initialize or check W and H\u001b[39;00m\n\u001b[1;32m-> 1702\u001b[0m W, H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_w_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_H\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;66;03m# scale the regularization terms\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m l1_reg_W, l1_reg_H, l2_reg_W, l2_reg_H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_regularization(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\decomposition\\_nmf.py:1254\u001b[0m, in \u001b[0;36m_BaseNMF._check_w_h\u001b[1;34m(self, X, W, H, update_H)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_components \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_components \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m-> 1254\u001b[0m     W, H \u001b[38;5;241m=\u001b[39m \u001b[43m_initialize_nmf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m W, H\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\decomposition\\_nmf.py:284\u001b[0m, in \u001b[0;36m_initialize_nmf\u001b[1;34m(X, n_components, init, eps, random_state)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_nmf\u001b[39m(X, n_components, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Algorithms for NMF initialization.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m    Computes an initial guess for the non-negative\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    http://tinyurl.com/nndsvd\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNMF initialization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m     n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    288\u001b[0m         init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m n_components \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_samples, n_features)\n\u001b[0;32m    291\u001b[0m     ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1827\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1824\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[0;32m   1826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1827\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhom\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to NMF initialization."
     ]
    }
   ],
   "source": [
    "from topic_extraction import extraction_pipeline\n",
    "\n",
    "df_1 = extraction_pipeline(df_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
